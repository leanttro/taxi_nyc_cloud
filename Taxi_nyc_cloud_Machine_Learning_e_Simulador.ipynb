{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MACHINE LEARNING (AMOSTA 3 MILHÕES CORRIDAS):**"
      ],
      "metadata": {
        "id": "ySQ7Ny_2v8pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------------------------------"
      ],
      "metadata": {
        "id": "4IDoxx9z96PS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- # **OBJETIVO 1**: Ensinar um modelo a prever a coluna trip_duration_minutes com base em outras características da corrida com PySpark MLlib"
      ],
      "metadata": {
        "id": "kwBdWeITwEU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Preparando Ambiente e carregando dados:"
      ],
      "metadata": {
        "id": "V26LWPKgwM58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wk1A3Vis5Zy",
        "outputId": "c43ddd92-956f-4f7b-ddd6-3b6f3188a62b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passo 1: Instalando bibliotecas...\n",
            "--> Bibliotecas instaladas com sucesso.\n",
            "\n",
            "Passo 2: Autenticação de usuário...\n",
            "--> Usuário autenticado com sucesso!\n",
            "\n",
            "Passo 3: Iniciando e configurando a sessão Spark...\n",
            "(Esta parte pode demorar um pouco enquanto baixa o conector)\n",
            "--> Sessão Spark pronta para uso!\n",
            "\n",
            "Passo 4: Carregando dados da tabela 'leanttro-projeto-taxi.dados_analise.dados_limpos'...\n",
            "\n",
            "========================================\n",
            " ✅ SUCESSO! DADOS CARREGADOS!\n",
            "========================================\n",
            "Total de registros carregados: 3000000\n",
            "\n",
            "Schema do DataFrame:\n",
            "root\n",
            " |-- VendorID: long (nullable = true)\n",
            " |-- tpep_pickup_datetime: string (nullable = true)\n",
            " |-- tpep_dropoff_datetime: string (nullable = true)\n",
            " |-- pickup_date: date (nullable = true)\n",
            " |-- pickup_day_of_week: long (nullable = true)\n",
            " |-- pickup_hour: long (nullable = true)\n",
            " |-- trip_duration_minutes: long (nullable = true)\n",
            " |-- passenger_count: double (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Passo 1: Instalando bibliotecas...\")\n",
        "!pip install pyspark google-cloud-bigquery pandas-gbq db-dtypes -q\n",
        "print(\"--> Bibliotecas instaladas com sucesso.\\n\")\n",
        "from pyspark.sql import SparkSession\n",
        "from google.colab import auth\n",
        "\n",
        "print(\"Passo 2: Autenticação de usuário...\")\n",
        "auth.authenticate_user()\n",
        "print(\"--> Usuário autenticado com sucesso!\\n\")\n",
        "\n",
        "\n",
        "print(\"Passo 3: Iniciando e configurando a sessão Spark...\")\n",
        "print(\"(Esta parte pode demorar um pouco enquanto baixa o conector)\")\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark-BigQuery-Conexao-Nova\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.34.0\") \\\n",
        "    .getOrCreate()\n",
        "print(\"--> Sessão Spark pronta para uso!\\n\")\n",
        "\n",
        "# Definição das variáveis e leitura dos dados do BigQuery\n",
        "project_id = 'leanttro-projeto-taxi'\n",
        "table_id = 'dados_analise.dados_limpos'\n",
        "\n",
        "print(f\"Passo 4: Carregando dados da tabela '{project_id}.{table_id}'...\")\n",
        "try:\n",
        "    # Este é o código de leitura que você enviou, que está correto.\n",
        "    # Ele vai usar a sessão 'spark' que acabamos de criar e configurar.\n",
        "    df_silver_completo = spark.read.format('bigquery') \\\n",
        "      .option('table', f'{project_id}.{table_id}') \\\n",
        "      .option('parentProject', project_id) \\\n",
        "      .load() \\\n",
        "      .limit(3000000)\n",
        "\n",
        "    # Coloca os dados em memória para acesso rápido\n",
        "    df_silver_completo.cache()\n",
        "\n",
        "    print(\"\\n========================================\")\n",
        "    print(\" ✅ SUCESSO! DADOS CARREGADOS!\")\n",
        "    print(\"========================================\")\n",
        "    print(f\"Total de registros carregados: {df_silver_completo.count()}\")\n",
        "    print(\"\\nSchema do DataFrame:\")\n",
        "    df_silver_completo.printSchema()\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"\\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "    print(\" ❌ FALHA AO CARREGAR OS DADOS.\")\n",
        "    print(\" O erro foi:\")\n",
        "    print(e)\n",
        "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Separando Colunas e Garantindo Limpeza:"
      ],
      "metadata": {
        "id": "B4FWCFNuwVL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_modelo = df_silver_completo.select(\n",
        "    \"pickup_hour\",\n",
        "    \"pickup_day_of_week\",\n",
        "    \"trip_distance\",\n",
        "    \"passenger_count\",\n",
        "    \"trip_duration_minutes\",\n",
        "    \"total_amount\"\n",
        ").na.drop()"
      ],
      "metadata": {
        "id": "vL12qhNOuKlw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dividindo os dados em treino (80%) e teste (20%):"
      ],
      "metadata": {
        "id": "x2gOu1Ybwe9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(df_treino, df_teste) = df_modelo.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "USDwV2ICuNU3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  Colocando em cache novamente:"
      ],
      "metadata": {
        "id": "7GMqCN5MwhKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino.cache()\n",
        "df_teste.cache()\n",
        "print(f\"Dados prontos para o modelo. Treino: {df_treino.count()}, Teste: {df_teste.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78A2-kl_urh3",
        "outputId": "f9d0c420-0c11-409c-c203-64396fb4e9bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados prontos para o modelo. Treino: 2399681, Teste: 600319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ".cache(): É uma otimização do Spark para guardar esses dois conjuntos de dados na memória, tornando o acesso a eles mais rápido nas etapas seguintes de treinamento."
      ],
      "metadata": {
        "id": "iPHw9M1NwlJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando as Features:"
      ],
      "metadata": {
        "id": "RXabe4lTwsay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "features_cols = [\"pickup_hour\", \"pickup_day_of_week\", \"trip_distance\", \"passenger_count\"]\n",
        "assembler = VectorAssembler(inputCols=features_cols, outputCol=\"features\")\n",
        "\n",
        "# Transformando os dataframes de treino e teste:\n",
        "df_treino_ml = assembler.transform(df_treino)\n",
        "df_teste_ml = assembler.transform(df_teste)"
      ],
      "metadata": {
        "id": "pJagqzCtwonj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELO DE ML:** Regressão Linear"
      ],
      "metadata": {
        "id": "zgefbgvnwxiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Carregar dados:\n"
      ],
      "metadata": {
        "id": "m0KyFmRPw2Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"trip_duration_minutes\")\n",
        "lr_modelo = lr.fit(df_treino_ml)\n"
      ],
      "metadata": {
        "id": "fa1ccHeEw826"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- # FAZENDO PREVISÕES:"
      ],
      "metadata": {
        "id": "P6mN6fIRw9kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes_lr = lr_modelo.transform(df_teste_ml)"
      ],
      "metadata": {
        "id": "U1JMUB9pxDZR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Avaliando modelo:"
      ],
      "metadata": {
        "id": "i_S56MAhxF4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = RegressionEvaluator(labelCol=\"trip_duration_minutes\", predictionCol=\"prediction\")\n",
        "rmse_lr = evaluator.evaluate(previsoes_lr, {evaluator.metricName: \"rmse\"})\n",
        "r2_lr = evaluator.evaluate(previsoes_lr, {evaluator.metricName: \"r2\"})"
      ],
      "metadata": {
        "id": "48InE4hBxH_Z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "bRDCqXP5ymyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- # Resultado do **Modelo LINEAR**:"
      ],
      "metadata": {
        "id": "49R1tQjTxQ7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Resultado da Regressão Linear ---\")\n",
        "print(f\"RMSE: {rmse_lr:.2f} minutos\")\n",
        "print(f\"R²: {r2_lr:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dd26XbwxUwp",
        "outputId": "9fca7dc9-3b34-464a-8898-093521cc77e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultado da Regressão Linear ---\n",
            "RMSE: 14.98 minutos\n",
            "R²: -13.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE: Ele pode errar até 14.98 min pra mais ou pra menos do que a duração da viagem!\n",
        "\n",
        "Um R² negativo, como na amostra inferior, é considerado muito baixo. Ele está ativamente fazendo previsões ruins. POR ISSO, vamos treinar OUTRO modelo e avaliar novamente:"
      ],
      "metadata": {
        "id": "0n2mXaM6xatR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ivDzN96dyvY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELO DE ML:** Random Forest"
      ],
      "metadata": {
        "id": "AOjyiNkFxynQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n_estimators=50 significa que ele usará 50 \"árvores de decisão\" para votar na melhor previsão.\n",
        "n_jobs=-1 usa todos os processadores disponíveis para acelerar o treinamento."
      ],
      "metadata": {
        "id": "2p67-d8gx4YI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Carregando dados:"
      ],
      "metadata": {
        "id": "ZugyNz8Gx_54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "rf = RandomForestRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"trip_duration_minutes\",\n",
        "    seed=42,\n",
        "    numTrees=50  # Equivalente ao n_estimators\n",
        ")\n",
        "rf_modelo = rf.fit(df_treino_ml)"
      ],
      "metadata": {
        "id": "2P0c90qex1rw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fazendo previsões:"
      ],
      "metadata": {
        "id": "9YzKo-WNx67g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previsoes_rf = rf_modelo.transform(df_teste_ml)"
      ],
      "metadata": {
        "id": "f5L-zwHFx9SZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Avaliando o modelo (usando o mesmo 'evaluator' de antes):\n"
      ],
      "metadata": {
        "id": "0vRnRCLzyDRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_rf = evaluator.evaluate(previsoes_rf, {evaluator.metricName: \"rmse\"})\n",
        "r2_rf = evaluator.evaluate(previsoes_rf, {evaluator.metricName: \"r2\"})"
      ],
      "metadata": {
        "id": "qRoDdA_5yFoA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "2C7PeAaOyzHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- # Resultado do **Modelo RANDOM Forest**:"
      ],
      "metadata": {
        "id": "zfMARszNyH7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Resultado do Random Forest ---\")\n",
        "print(f\"RMSE: {rmse_rf:.2f} minutos\")\n",
        "print(f\"R²: {r2_rf:.2%}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Q-Nl9DyKAw",
        "outputId": "4dc89880-f0ec-4a1d-8eee-9529e63e7b82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultado do Random Forest ---\n",
            "RMSE: 7.60 minutos\n",
            "R²: 70.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "%md\n",
        "RMSE: Ele pode errar até 7.60 min pra mais ou pra menos do que a duração da viagem!\n",
        "\n",
        "Um R² de 70.77% significa que ele pode acertar mais que 2/3 das previsões! Bem melhor do que o modelo de regressão linear para esse caso!\n",
        "\n",
        "**OU SEJA, OBTEVE UM RESULTADO MELHOR QUE O PRIMEIRO TESTE!**"
      ],
      "metadata": {
        "id": "71KpVhMQy6R2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "geO43rxqyzke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- # **OBJETIVO 2**: Ensinar um modelo a prever a coluna total_amount com base nas características da corrida, incluindo a duração que nosso primeiro modelo previa usando PySpark MLlib"
      ],
      "metadata": {
        "id": "Q0q8iPT_zF1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELO DE ML:** Random Forest Regressor\n"
      ],
      "metadata": {
        "id": "-3H1eS2NzLLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Criando coluna \"Duração Prevista\":"
      ],
      "metadata": {
        "id": "iDe_0tM6zhKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_treino_com_previsao_tempo = rf_modelo.transform(df_treino_ml) \\\n",
        "                                        .withColumnRenamed(\"prediction\", \"duracao_prevista\")\n",
        "df_teste_com_previsao_tempo = rf_modelo.transform(df_teste_ml) \\\n",
        "                                       .withColumnRenamed(\"prediction\", \"duracao_prevista\")\n",
        "\n",
        "print(\"Coluna 'duracao_prevista' criada com sucesso.\")\n",
        "df_treino_com_previsao_tempo.select(\"trip_duration_minutes\", \"duracao_prevista\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_MbJ5KFze5l",
        "outputId": "df088898-14dc-470d-f5fd-b1138a21a334"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coluna 'duracao_prevista' criada com sucesso.\n",
            "+---------------------+-----------------+\n",
            "|trip_duration_minutes| duracao_prevista|\n",
            "+---------------------+-----------------+\n",
            "|                    6|7.412289584410088|\n",
            "|                    6|7.440934449947852|\n",
            "|                    2|7.412289584410088|\n",
            "|                    2|7.440934449947852|\n",
            "|                    2|7.412289584410088|\n",
            "+---------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Criando Features:"
      ],
      "metadata": {
        "id": "ctg6dLHDzkwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "features_valor_cols = [\n",
        "    \"pickup_hour\",\n",
        "    \"pickup_day_of_week\",\n",
        "    \"trip_distance\",\n",
        "    \"passenger_count\",\n",
        "    \"duracao_prevista\"  # <<< A previsão do primeiro modelo entra aqui!\n",
        "]\n",
        "assembler_valor = VectorAssembler(inputCols=features_valor_cols, outputCol=\"features_valor\")\n",
        "df_treino_valor = assembler_valor.transform(df_treino_com_previsao_tempo)\n",
        "df_teste_valor = assembler_valor.transform(df_teste_com_previsao_tempo)\n",
        "print(\"Features para o modelo de valor preparadas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-0g2ZD-znEd",
        "outputId": "27288672-597a-4d23-eb6c-e0a618d42503"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features para o modelo de valor preparadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Carrendo dados focado no valor (total_amount):"
      ],
      "metadata": {
        "id": "3jZViN7qzpYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "rf_valor = RandomForestRegressor(\n",
        "    featuresCol=\"features_valor\",\n",
        "    labelCol=\"total_amount\", # <-- Added the labelCol here\n",
        "    seed=42,\n",
        "    numTrees=50\n",
        ")"
      ],
      "metadata": {
        "id": "g_uf0vrGzrX1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Treinando modelo:"
      ],
      "metadata": {
        "id": "dmFls6csztCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "modelo_valor = rf_valor.fit(df_treino_valor)\n",
        "print(\"Treinamento concluído!\")\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "previsoes_valor = modelo_valor.transform(df_teste_valor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJNfI5q6z32N",
        "outputId": "284d2bf3-265f-4ca9-d1bd-a86b244c4e4b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinamento concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Avaliando o modelo:"
      ],
      "metadata": {
        "id": "6FPJN7Ll0DyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_valor = RegressionEvaluator(labelCol=\"total_amount\", predictionCol=\"prediction\")\n",
        "rmse_valor = evaluator_valor.evaluate(previsoes_valor, {evaluator_valor.metricName: \"rmse\"})\n",
        "r2_valor = evaluator_valor.evaluate(previsoes_valor, {evaluator_valor.metricName: \"r2\"})"
      ],
      "metadata": {
        "id": "uYfS9LUC0K7m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "SsMgayJO0YHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- # Resultado do **Modelo RANDOM Forest Regressor**:"
      ],
      "metadata": {
        "id": "M6XcQGa60Mzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Resultado do Modelo de Previsão de Valor ---\")\n",
        "print(f\"RMSE: ${rmse_valor:.2f} DÓLARES\")\n",
        "print(f\"R²: {r2_valor:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SduyajiB0Pbk",
        "outputId": "3bfdd6b4-ba7d-4108-c38d-aef5035baa94"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultado do Modelo de Previsão de Valor ---\n",
            "RMSE: $9.24 DÓLARES\n",
            "R²: 83.69%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE: O valor está $9,24 DÓLARES de diferença (pra mais ou pra menos) do valor real, considerando todas as variações que podem alterar no valor final\n",
        "\n",
        "R²: 83.69% significa que o modelo  consegue captar bem a relação entre as variáveis (tempo, distância, hora, etc.) e o preço."
      ],
      "metadata": {
        "id": "3HvxJ4mH0UNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "UJFmTb7Z0Yj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **------------ SIMULADOR PARA CORRIDA: VALORES E TEMPO ------------**\n",
        "- # (AMOSTRA 3 MILHÕES DE CORRIDAS):"
      ],
      "metadata": {
        "id": "z0yPeFj30diM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Selecionar colunas e remover nulos\n",
        "df_modelo =  df_silver_completo.select(\n",
        "    \"pickup_hour\",\n",
        "    \"pickup_day_of_week\",\n",
        "    \"trip_distance\",\n",
        "    \"passenger_count\",\n",
        "    \"trip_duration_minutes\",\n",
        "    \"total_amount\"\n",
        ").na.drop()\n",
        "\n",
        "# Preparar o assembler de features para o primeiro modelo\n",
        "features_cols_tempo = [\"pickup_hour\", \"pickup_day_of_week\", \"trip_distance\", \"passenger_count\"]\n",
        "assembler_tempo = VectorAssembler(inputCols=features_cols_tempo, outputCol=\"features\")\n",
        "\n",
        "# Transformar os dados e dividir em treino e teste\n",
        "df_transformado_tempo = assembler_tempo.transform(df_modelo)\n",
        "(df_treino_tempo, df_teste_tempo) = df_transformado_tempo.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Colocar em cache para performance\n",
        "df_treino_tempo.cache()\n",
        "df_teste_tempo.cache()\n",
        "\n",
        "print(\"Dados preparados e divididos para o modelo de DURAÇÃO.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFkRFd_g49Xu",
        "outputId": "fa1ee56b-54a6-4ba7-fd84-737ce9cd207f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados preparados e divididos para o modelo de DURAÇÃO.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Treinando Modelo TEMPO (Modelo Random Forest Regressor):"
      ],
      "metadata": {
        "id": "_ge91sFw381F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "# Configurar o modelo\n",
        "rf_tempo = RandomForestRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"trip_duration_minutes\",\n",
        "    seed=42,\n",
        "    numTrees=50\n",
        ")\n",
        "\n",
        "# Treinar o modelo\n",
        "print(\"Treinando o modelo de previsão de tempo... (Isso pode levar alguns minutos)\")\n",
        "rf_modelo_tempo = rf_tempo.fit(df_treino_tempo)\n",
        "\n",
        "# SALVAR O MODELO TREINADO (PASSO CRUCIAL)\n",
        "rf_modelo_tempo.write().overwrite().save(\"./modelo_tempo_spark\")\n",
        "\n",
        "print(\"Modelo de DURAÇÃO treinado e salvo com sucesso na pasta './modelo_tempo_spark'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46fRYTfp3_Id",
        "outputId": "07148248-0d10-4142-8c4a-1b63340a9176"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando o modelo de previsão de tempo... (Isso pode levar alguns minutos)\n",
            "Modelo de DURAÇÃO treinado e salvo com sucesso na pasta './modelo_tempo_spark'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Treinando Modelo VALOR (Modelo Randon Forest Regressor) :"
      ],
      "metadata": {
        "id": "tyJrYf1z2Uuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "df_treino_com_previsao_tempo = rf_modelo_tempo.transform(df_treino_tempo) \\\n",
        "                                              .withColumnRenamed(\"prediction\", \"duracao_prevista\")\n",
        "\n",
        "features_cols_valor = [\n",
        "    \"pickup_hour\",\n",
        "    \"pickup_day_of_week\",\n",
        "    \"trip_distance\",\n",
        "    \"passenger_count\",\n",
        "    \"duracao_prevista\" # Usando a previsão do primeiro modelo como feature\n",
        "]\n",
        "assembler_valor = VectorAssembler(inputCols=features_cols_valor, outputCol=\"features_valor\")\n",
        "df_treino_valor = assembler_valor.transform(df_treino_com_previsao_tempo)\n",
        "\n",
        "rf_valor = RandomForestRegressor(\n",
        "    featuresCol=\"features_valor\",\n",
        "    labelCol=\"total_amount\", # Agora o alvo é o valor total\n",
        "    seed=42,\n",
        "    numTrees=50\n",
        ")\n",
        "\n",
        "print(\"Treinando o modelo de previsão de valor... (Isso também pode demorar)\")\n",
        "modelo_valor = rf_valor.fit(df_treino_valor)\n",
        "\n",
        "#  SALVANDO O SEGUNDO MODELO TREINADO\n",
        "modelo_valor.write().overwrite().save(\"./modelo_valor_spark\")\n",
        "\n",
        "print(\"Modelo de VALOR treinado e salvo com sucesso na pasta './modelo_valor_spark'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOBtd1do2dwP",
        "outputId": "14c32aa6-e715-425e-a1a7-684893bcab14"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treinando o modelo de previsão de valor... (Isso também pode demorar)\n",
            "Modelo de VALOR treinado e salvo com sucesso na pasta './modelo_valor_spark'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Executando Simulador:"
      ],
      "metadata": {
        "id": "1_spy1oY2hf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressionModel\n",
        "def simular_corrida_spark_completo(km, hora, dia_semana, passageiros=1):\n",
        "    try:\n",
        "        modelo_tempo = RandomForestRegressionModel.load(\"./modelo_tempo_spark\")\n",
        "        modelo_valor = RandomForestRegressionModel.load(\"./modelo_valor_spark\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar os modelos. Certifique-se de que as pastas './modelo_tempo_spark' e './modelo_valor_spark' existem.\")\n",
        "        print(f\"Detalhe do erro: {e}\")\n",
        "        return\n",
        "\n",
        "    milhas = km * 0.621371\n",
        "    schema_inicial = \"pickup_hour INT, pickup_day_of_week INT, trip_distance DOUBLE, passenger_count INT\"\n",
        "    dados_nova_corrida = spark.createDataFrame(\n",
        "        data=[(hora, dia_semana, milhas, passageiros)],\n",
        "        schema=schema_inicial\n",
        "    )\n",
        "\n",
        "    # Transforma os dados de entrada usando o primeiro assembler (para o modelo de tempo)\n",
        "    dados_para_prever_tempo = assembler.transform(dados_nova_corrida)\n",
        "    # Faz a previsão do tempo e renomeia a coluna de previsão para 'duracao_prevista'\n",
        "    df_com_duracao_prevista = modelo_tempo.transform(dados_para_prever_tempo).withColumnRenamed(\"prediction\", \"duracao_prevista\")\n",
        "\n",
        "    duracao_prevista = df_com_duracao_prevista.select(\"duracao_prevista\").first()[0]\n",
        "\n",
        "    # Transforma o DataFrame (que agora tem a 'duracao_prevista') usando o segundo assembler (para o modelo de valor)\n",
        "    dados_para_prever_valor = assembler_valor.transform(df_com_duracao_prevista)\n",
        "\n",
        "    # Faz a previsão do valor\n",
        "    previsao_valor_df = modelo_valor.transform(dados_para_prever_valor)\n",
        "\n",
        "    # Extrai o resultado da previsão de valor\n",
        "    valor_previsto = previsao_valor_df.select(\"prediction\").first()[0]\n",
        "\n",
        "\n",
        "    print(\"\\n--- Previsão da Corrida (PySpark) ---\")\n",
        "    print(f\"Distância: {km:.2f} km\")\n",
        "    print(f\"Hora: {hora}:00h\")\n",
        "    print(f\"Dia da semana: {dia_semana}\")\n",
        "    print(f\">> Tempo estimado: {duracao_prevista:.1f} min\")\n",
        "    print(f\">> Valor estimado: ${valor_previsto:.2f}\")\n",
        "\n",
        "\n",
        "# --- Parte Interativa ---\n",
        "# (Pede os dados para o usuário e chama a função completa)\n",
        "try:\n",
        "    print(\"\\n--- Simulador de Corrida Interativo (PySpark) ---\")\n",
        "    km_usuario = float(input(\"Digite a distância da corrida em KM (ex: 12.5): \"))\n",
        "    hora_usuario = int(input(\"Digite a hora do dia (0 a 23): \"))\n",
        "    dia_semana_usuario = int(input(\"Digite o dia da semana (1=Dom, 2=Seg, ..., 7=Sáb): \"))\n",
        "\n",
        "    simular_corrida_spark_completo(km_usuario, hora_usuario, dia_semana_usuario)\n",
        "\n",
        "except ValueError:\n",
        "    print(\"\\nErro: Entrada inválida.\")\n",
        "except NameError:\n",
        "    print(\"\\nErro: Os 'assemblers' não foram definidos. Execute o código de treinamento primeiro.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzXyqHCD08eb",
        "outputId": "6221894e-1bb4-4dfb-be7b-180d6fa0486e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Simulador de Corrida Interativo (PySpark) ---\n",
            "Digite a distância da corrida em KM (ex: 12.5): 25\n",
            "Digite a hora do dia (0 a 23): 23\n",
            "Digite o dia da semana (1=Dom, 2=Seg, ..., 7=Sáb): 7\n",
            "\n",
            "--- Previsão da Corrida (PySpark) ---\n",
            "Distância: 25.00 km\n",
            "Hora: 23:00h\n",
            "Dia da semana: 7\n",
            ">> Tempo estimado: 37.9 min\n",
            ">> Valor estimado: $80.96\n"
          ]
        }
      ]
    }
  ]
}